{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_mnist.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/gan/gan_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will build a generative adversarial network (GAN) trained on the MNIST dataset. From this we will be able to generate new handwritten digits. \n",
        "\n",
        "The process will be broken down into the following steps:\n",
        "\n",
        "  1. Load and visualize the dataset\n",
        "  2. Define a model\n",
        "      - Define a discriminator network\n",
        "      - Define a generator network\n",
        "      - Build complete network\n",
        "  3. Specify loss functions and optimizers\n",
        "  4. Train the model\n",
        "      - Discriminator training\n",
        "          * Compute the discriminator loss on real images\n",
        "          * Generate fake images\n",
        "          * Compute the discriminator loss on fake, generated images\n",
        "          * Add up real and fale losses\n",
        "          * Update discriminator's weights (backprop + optimization)\n",
        "      - Generator training\n",
        "          * Generate fake images\n",
        "          * Compute the discriminator loss on fake images using flipped labels\n",
        "          * Update generator's weights (backprop + optimization)\n",
        "  5. Generate new images\n"
      ],
      "metadata": {
        "id": "iC8Cfgstas6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "TR2XozawMDIO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available!\")\n",
        "\n",
        "device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGb712qpZo-I",
        "outputId": "6a5af1c1-ee34-49e9-fed0-eaa3219976e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and visualiza dataset"
      ],
      "metadata": {
        "id": "mhTqOKj_nPE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# load dataset from torchvision.datasets \n",
        "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# number of subprocess to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "\n",
        "# prepare dataloader\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "# image classes in the dataset\n",
        "classes = ['0','1','2','3','4','5', '6','7','8','9']\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "id": "GhIbONz-mu9G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out some data stats\n",
        "\n",
        "print('Number of training images:', len(train_data))\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(\"Image batch dimensions:\", inputs.shape)\n",
        "  print(\"Image label dimensions:\", targets.shape)\n",
        "  print(\"Class labels of 10 examples:\", targets[:10])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jayuhk8vpjD8",
        "outputId": "b4e3b2d4-cd3e-47df-d83a-079fdf83f503"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 60000\n",
            "Image batch dimensions: torch.Size([32, 1, 28, 28])\n",
            "Image label dimensions: torch.Size([32])\n",
            "Class labels of 10 examples: tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize a batch of training data\n",
        "\n",
        "def imshow(img):\n",
        "  plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
        "\n",
        "# obtain one batch on training images\n",
        "dataiter = iter(train_loader)\n",
        "inputs, targets = dataiter.next()\n",
        "inputs = inputs.numpy()\n",
        "\n",
        "# plot some images in the batch along with the corresponding labels\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "for idx in np.arange(10):\n",
        "  ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
        "  imshow(inputs[idx])\n",
        "  ax.set_title(str(targets[idx].item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_TK2Ezk8sthd",
        "outputId": "16194a06-ecb1-4743-8980-c626b8e03ff2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ],
      "metadata": {
        "id": "s3BeL45l0iFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator network\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_dim * 4)\n",
        "    self.fc2 = nn.Linear(hidden_dim * 4, hidden_dim * 2)\n",
        "    self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "    self.fc4 = nn.Linear(hidden_dim, output_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    out = self.fc4(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "a9GHrHAbzFr2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator network\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
        "    self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim * 4)\n",
        "    self.fc4 = nn.Linear(hidden_dim * 4, output_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    out = F.tanh(self.fc4(x))\n",
        "    return out"
      ],
      "metadata": {
        "id": "JD-euqXl8Y-7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator hyparameters\n",
        "\n",
        "# size of the input image to discriminator \n",
        "input_size = 28*28\n",
        "# size of the discriminator output\n",
        "d_output_size = 1\n",
        "# size of the last hidden layer\n",
        "d_hidden_size = 32\n",
        "\n",
        "# Generator hyperparameters\n",
        "\n",
        "# size of the latent vector\n",
        "z_size = 100\n",
        "# size of the generator output\n",
        "g_output_size = 28*28\n",
        "# size of the first hidden layer\n",
        "g_hidden_size = 32\n",
        "\n",
        "# Build complete network\n",
        "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
        "G = Generator(z_size, g_hidden_size, g_output_size)\n",
        "\n",
        "print(D)\n",
        "print()\n",
        "print(G)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e1CX5f9o7D",
        "outputId": "21e476f7-cea0-46da-d5b1-f21327a79a6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=784, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify loss functions and optimizers"
      ],
      "metadata": {
        "id": "BsI4fzGx_y9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# real image loss\n",
        "def real_loss(D_out, smooth=False):\n",
        "  batch_size = D_out.size(0)\n",
        "  # label smoothing\n",
        "  labels = torch.ones(batch_size) * 0.9 if smooth else torch.ones(batch_size) \n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(D_out.squeeze(), labels)\n",
        "  return loss\n",
        "\n",
        "# fake image loss\n",
        "def fake_loss(D_out):\n",
        "  batch_size = D_out.size(0)\n",
        "  labels = torch.zeros(batch_size)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(D_out.squeeze(), labels)\n",
        "  return loss "
      ],
      "metadata": {
        "id": "7cEmB2ODCW8r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify optimizer\n",
        "lr = 0.0001\n",
        "\n",
        "# optimizer for discriminator\n",
        "d_optimizer = optim.Adam(D.parameters(), lr)\n",
        "# optimizer for generator\n",
        "g_optimizer = optim.Adam(G.parameters(), lr)"
      ],
      "metadata": {
        "id": "jE4Lkx7kVcDT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "QFns9-YnCXdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6Qozq86i_FOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate new images"
      ],
      "metadata": {
        "id": "xOpuEUFfCo_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LnQpdB_h_FTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}