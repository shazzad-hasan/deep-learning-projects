{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_mnist.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/gan/gan_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will build a generative adversarial network (GAN) trained on the MNIST dataset. From this we will be able to generate new handwritten digits. \n",
        "\n",
        "The process will be broken down into the following steps:\n",
        "\n",
        "  1. Load and visualize the dataset\n",
        "  2. Define a model\n",
        "      - Define a discriminator network\n",
        "      - Define a generator network\n",
        "      - Build complete network\n",
        "  3. Specify loss functions and optimizers\n",
        "  4. Train the model\n",
        "      - Discriminator training\n",
        "          * Compute the discriminator loss on real images\n",
        "          * Generate fake images\n",
        "          * Compute the discriminator loss on fake, generated images\n",
        "          * Add up real and fale losses\n",
        "          * Update discriminator's weights (backprop + optimization)\n",
        "      - Generator training\n",
        "          * Generate fake images\n",
        "          * Compute the discriminator loss on fake images using flipped labels\n",
        "          * Update generator's weights (backprop + optimization)\n",
        "  5. Generate new images\n"
      ],
      "metadata": {
        "id": "iC8Cfgstas6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "TR2XozawMDIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available!\")\n",
        "\n",
        "device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "RGb712qpZo-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and visualiza dataset"
      ],
      "metadata": {
        "id": "mhTqOKj_nPE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# load dataset from torchvision.datasets \n",
        "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# number of subprocess to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "\n",
        "# prepare dataloader\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "# image classes in the dataset\n",
        "classes = ['0','1','2','3','4','5', '6','7','8','9']\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "id": "GhIbONz-mu9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print out some data stats\n",
        "\n",
        "print('Number of training images:', len(train_data))\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(\"Image batch dimensions:\", inputs.shape)\n",
        "  print(\"Image label dimensions:\", targets.shape)\n",
        "  print(\"Class labels of 10 examples:\", targets[:10])\n",
        "  break"
      ],
      "metadata": {
        "id": "Jayuhk8vpjD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize a batch of training data\n",
        "\n",
        "def imshow(img):\n",
        "  plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
        "\n",
        "# obtain one batch on training images\n",
        "dataiter = iter(train_loader)\n",
        "inputs, targets = dataiter.next()\n",
        "inputs = inputs.numpy()\n",
        "\n",
        "# plot some images in the batch along with the corresponding labels\n",
        "fig = plt.figure(figsize=(10, 4))\n",
        "for idx in np.arange(10):\n",
        "  ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n",
        "  imshow(inputs[idx])\n",
        "  ax.set_title(str(targets[idx].item()))"
      ],
      "metadata": {
        "id": "_TK2Ezk8sthd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ],
      "metadata": {
        "id": "s3BeL45l0iFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator network\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_dim * 4)\n",
        "    self.fc2 = nn.Linear(hidden_dim * 4, hidden_dim * 2)\n",
        "    self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "    self.fc4 = nn.Linear(hidden_dim, output_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    out = self.fc4(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "a9GHrHAbzFr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator network\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_size, hidden_dim, output_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
        "    self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim * 4)\n",
        "    self.fc4 = nn.Linear(hidden_dim * 4, output_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "    x = self.dropout(x)\n",
        "    out = F.tanh(self.fc4(x))\n",
        "    return out"
      ],
      "metadata": {
        "id": "JD-euqXl8Y-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator hyparameters\n",
        "\n",
        "# size of the input image to discriminator \n",
        "input_size = 28*28\n",
        "# size of the discriminator output\n",
        "d_output_size = 1\n",
        "# size of the last hidden layer\n",
        "d_hidden_size = 32\n",
        "\n",
        "# Generator hyperparameters\n",
        "\n",
        "# size of the latent vector\n",
        "z_size = 100\n",
        "# size of the generator output\n",
        "g_output_size = 28*28\n",
        "# size of the first hidden layer\n",
        "g_hidden_size = 32\n",
        "\n",
        "# Build complete network\n",
        "D = Discriminator(input_size, d_hidden_size, d_output_size).to(device)\n",
        "G = Generator(z_size, g_hidden_size, g_output_size).to(device)\n",
        "\n",
        "\n",
        "\n",
        "print(D)\n",
        "print()\n",
        "print(G)"
      ],
      "metadata": {
        "id": "01e1CX5f9o7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify loss functions and optimizers"
      ],
      "metadata": {
        "id": "BsI4fzGx_y9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# real image loss\n",
        "def real_loss(D_out, smooth=False):\n",
        "  batch_size = D_out.size(0)\n",
        "  # label smoothing\n",
        "  labels = torch.ones(batch_size).to(device) * 0.9 if smooth else torch.ones(batch_size).to(device)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(D_out.squeeze(), labels)\n",
        "  return loss\n",
        "\n",
        "# fake image loss\n",
        "def fake_loss(D_out):\n",
        "  batch_size = D_out.size(0)\n",
        "  labels = torch.zeros(batch_size).to(device)\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  loss = criterion(D_out.squeeze(), labels)\n",
        "  return loss "
      ],
      "metadata": {
        "id": "7cEmB2ODCW8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify optimizer\n",
        "lr = 0.0001\n",
        "\n",
        "# optimizer for discriminator\n",
        "d_optimizer = optim.Adam(D.parameters(), lr)\n",
        "# optimizer for generator\n",
        "g_optimizer = optim.Adam(G.parameters(), lr)"
      ],
      "metadata": {
        "id": "jE4Lkx7kVcDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "QFns9-YnCXdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "num_epochs = 5\n",
        "\n",
        "# track training losses\n",
        "losses = []\n",
        "\n",
        "# Get some fixed data for sampling. These are images that are held\n",
        "# constant throughout training, and allow us to inspect the model's performance\n",
        "sample_size=16\n",
        "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "fixed_z = torch.from_numpy(fixed_z).float()\n",
        "fixed_z = fixed_z.to(device)\n",
        "\n",
        "# set models to training mode\n",
        "D.train()\n",
        "G.train()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
        "\n",
        "        # move tensor to the right device                \n",
        "        real_images = real_images.to(device)\n",
        "        # rescale input images from [0,1) to [-1, 1)\n",
        "        real_images = real_images * 2 - 1 \n",
        "\n",
        "        batch_size = real_images.size(0)\n",
        "        \n",
        "        # ----------- train the discriminator ------------\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        ### Train with real images\n",
        "\n",
        "        # compute the discriminator losses on real images and smooth the real labels\n",
        "        D_real = D(real_images)\n",
        "        d_real_loss = real_loss(D_real, smooth=True)\n",
        "        \n",
        "        ###  Train with fake images\n",
        "        \n",
        "        # generate fake images\n",
        "        with torch.no_grad():\n",
        "            z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "            z = torch.from_numpy(z).float()\n",
        "            z = z.to(device)\n",
        "            fake_images = G(z)\n",
        "        \n",
        "        # compute the discriminator losses on fake images        \n",
        "        D_fake = D(fake_images)\n",
        "        d_fake_loss = fake_loss(D_fake)\n",
        "        \n",
        "        # add up losses\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        # backward pass\n",
        "        d_loss.backward()\n",
        "        # update parameters\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        \n",
        "        # ----------- train the generator -------------\n",
        "\n",
        "        # clear the gradients of all optimized variables\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        ### Train with fake images and flipped labels\n",
        "        \n",
        "        # Generate fake images\n",
        "        z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        z = z.to(device)\n",
        "        fake_images = G(z)\n",
        "        \n",
        "        # compute the discriminator losses on fake images using flipped labels\n",
        "        D_fake = D(fake_images)\n",
        "        g_loss = real_loss(D_fake)\n",
        "        \n",
        "        # backward pass\n",
        "        g_loss.backward()\n",
        "        # update parameters\n",
        "        g_optimizer.step()\n",
        "\n",
        "    print('Epoch {:5d} | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "            epoch+1, d_loss.item(), g_loss.item()))\n",
        "\n",
        "    losses.append((d_loss.item(), g_loss.item()))\n",
        "    \n",
        "    # set to evaluation mode\n",
        "    G.eval()\n",
        "    # generate samples\n",
        "    samples_z = G(fixed_z)\n",
        "    # set back to train mode\n",
        "    G.train()"
      ],
      "metadata": {
        "id": "YZUQaF5jD2zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate new images"
      ],
      "metadata": {
        "id": "xOpuEUFfCo_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LnQpdB_h_FTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}