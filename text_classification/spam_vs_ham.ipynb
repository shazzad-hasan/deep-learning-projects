{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spam_vs_ham.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/text_classification/spam_vs_ham.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g64cuofepDK"
      },
      "outputs": [],
      "source": [
        "# upload kaggle API key from your local machine\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a kaggle dir, copy the API key to it\n",
        "# and make sure the file in only readable by yourself (chmod 600)\n",
        "!mkdir ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "TaUiYMasgQbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use API command to download the dataset\n",
        "!kaggle datasets download -d uciml/sms-spam-collection-dataset"
      ],
      "metadata": {
        "id": "Jx-dUPRygZUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncompress the dataset\n",
        "!unzip -qq sms-spam-collection-dataset.zip"
      ],
      "metadata": {
        "id": "-rAuXQS4hEcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.9.1\n",
        "!pip install torch==1.8.1"
      ],
      "metadata": {
        "id": "maa4X1xUkhHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "0xFnve8DgZXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/spam.csv\", encoding=\"latin-1\")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "-zTCORd0gZar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "data = data.rename(index = str, columns = {\"v1\": \"labels\", \"v2\": \"text\"})\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "CIu5VD5vgZdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data, test_size = 0.2, random_state = 42)\n",
        "\n",
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "dk4cwJoPiOp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "zJfcP7M9iFIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)"
      ],
      "metadata": {
        "id": "ROFtlvnujWni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "5DJqMEOhj3Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "WnFYwD6gkEqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = Field(tokenize = word_tokenize)"
      ],
      "metadata": {
        "id": "9PM3ROa3wvCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL = Field(dtype = torch.float)"
      ],
      "metadata": {
        "id": "Aa4VkiF_w9uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafields = [(\"labels\", LABEL), (\"text\", TEXT)]"
      ],
      "metadata": {
        "id": "0DjM0CIaxNxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn, tst = TabularDataset.splits(path = './',\n",
        "                                        train = \"train.csv\",\n",
        "                                        test = \"test.csv\",\n",
        "                                        format = \"csv\",\n",
        "                                        skip_header = True,\n",
        "                                        fields = datafields)"
      ],
      "metadata": {
        "id": "RLX4LfWXxfOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn[:5]"
      ],
      "metadata": {
        "id": "bVWnf_2YyCSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(trn)}')\n",
        "print(f'Number of testing examples: {len(tst)}')"
      ],
      "metadata": {
        "id": "ooSxWeavZdVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn[5].__dict__.keys()"
      ],
      "metadata": {
        "id": "SR4NSCt4ZtY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn[5].text"
      ],
      "metadata": {
        "id": "Fde7RxmfZ33X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn[5].labels"
      ],
      "metadata": {
        "id": "cLmEvbbiaC93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(trn.examples[5]))"
      ],
      "metadata": {
        "id": "wKB99ADnaIcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(trn, max_size = 10500)"
      ],
      "metadata": {
        "id": "slaJjuUlaQXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.build_vocab(trn)"
      ],
      "metadata": {
        "id": "e9LmC9Lwaasv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}')\n",
        "print(f'Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}')"
      ],
      "metadata": {
        "id": "d0wkHYeKa8I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.freqs.most_common(50))"
      ],
      "metadata": {
        "id": "AOIWKB-kbG-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "metadata": {
        "id": "foMpA2aIbygi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "id": "K1oCus6_ghxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (trn, tst),\n",
        "    batch_size = batch_size,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = False)"
      ],
      "metadata": {
        "id": "KydvssJcgrDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import torch.nn as nn\n",
        "\n",
        " class RNN(nn.Module):\n",
        "   def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "     super().__init__()\n",
        "     self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "     self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "     self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "   def forward(self, text):\n",
        "     embedded = self.embedding(text)\n",
        "     output, hidden = self.rnn(embedded)\n",
        "     hidden_1D = hidden.squeeze(0)\n",
        "     assert torch.equal(output[-1, :, :], hidden_1D)\n",
        "     return self.fc(hidden_1D)"
      ],
      "metadata": {
        "id": "Y0tZlwQVhQVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "wskZsctGw8t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "XEzYVjbZx-L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):  \n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, batch in enumerate(iterator):\n",
        "    texts = batch.text\n",
        "    labels = batch.labels\n",
        "    labels = labels.unsqueeze(1)\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(texts)\n",
        "    loss = criterion(predictions, labels)\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (rounded_preds==batch.labels).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "sYVpLT1sBEaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "  print(f\"| Epoch: {epoch+1:02}  |Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:0.2f}%\")"
      ],
      "metadata": {
        "id": "qWGni6G526kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_loss = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch in test_iterator:\n",
        "    predictions = model(batch.text)\n",
        "    loss = criterion(predictions, (batch.labels).T)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}')"
      ],
      "metadata": {
        "id": "ItwpzJkZjf9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-1xl1QWDmT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, _) = self.rnn(embedded)\n",
        "    hidden_1D = hidden.squeeze(0)\n",
        "    return self.fc(hidden_1D)"
      ],
      "metadata": {
        "id": "FX3DB4UuDmeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(input_dim, embedding_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "Wlz7jkmnJIyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02}  Train Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "id": "A9AUHKfSJI1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_loss = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch in test_iterator:\n",
        "    predictions = model(batch.text)\n",
        "    loss = criterion(predictions, (batch.labels).T)\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "test_loss = epoch_loss / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}')"
      ],
      "metadata": {
        "id": "seOm-FzuJI4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}