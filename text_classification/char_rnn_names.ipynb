{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2m1nP9DXPTxlzjXeIa5bs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/text_classification/char_rnn_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evRwRIB7-ojc"
      },
      "outputs": [],
      "source": [
        "# import required libraries \n",
        "from io import open \n",
        "import glob \n",
        "import os\n",
        "\n",
        "import torch \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available\")\n",
        "else:\n",
        "  print(\"CUDA is not available\")\n",
        "\n",
        "device = torch.device('cuda') if train_on_gpu else torch.device('cpu')"
      ],
      "metadata": {
        "id": "S5UtmSqrTaX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and preprocess"
      ],
      "metadata": {
        "id": "8VULudaYUJUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "import unicodedata \n",
        "\n",
        "# all ascii characters including space, dot, comma, semicolon, single quote\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "all_letters"
      ],
      "metadata": {
        "id": "tDVI8-ZXXIXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unicodeToAscii(s):\n",
        "  \"\"\" \n",
        "    Convert unicode string to ascii string\n",
        "  \"\"\"\n",
        "  ascii_str = \"\"\n",
        "  for ch in unicodedata.normalize('NFD', s):\n",
        "    if unicodedata.category(ch) != \"Mn\":\n",
        "      if ch in all_letters:\n",
        "        ascii_str += ch\n",
        "  \n",
        "  return ascii_str\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))"
      ],
      "metadata": {
        "id": "x7N3iq17oar6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m4DDdS0u91rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/data/names/*.txt\"\n",
        "\n",
        "def findFiles(path): \n",
        "  return glob.glob(path)\n",
        "\n",
        "findFiles(data_path)"
      ],
      "metadata": {
        "id": "6IvQ7SgSl6xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_names = {}\n",
        "all_languages = []\n",
        "\n",
        "total_names = 0\n",
        "\n",
        "for filename in findFiles(data_path):\n",
        "    language = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_languages.append(language)\n",
        "    read_names = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    names = [unicodeToAscii(name) for name in read_names]\n",
        "    language_names[language] = names\n",
        "    total_names += len(names)\n",
        "\n",
        "n_languages = len(all_languages)"
      ],
      "metadata": {
        "id": "skT_mbP6oavD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_languages"
      ],
      "metadata": {
        "id": "fDv1twxz5Ns9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(language_names['Italian'][:10])"
      ],
      "metadata": {
        "id": "0JVSjA2R7jOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][all_letters.find(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('a'))"
      ],
      "metadata": {
        "id": "nBXdkrU58TdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nameToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][all_letters.find(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "jones_tensor = nameToTensor('Jones')\n",
        "\n",
        "print(jones_tensor.size())\n",
        "print(jones_tensor)"
      ],
      "metadata": {
        "id": "XtVZBhuN8TgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "xe4QR0fI_DLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 256\n",
        "model = RNN(n_letters, n_hidden, n_languages)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "F3O_UsK68TjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK5m_YPhKwm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "kDbXckiuDF37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define some helper functions\n",
        "\n",
        "import random\n",
        "\n",
        "def languageFromOutput(output):\n",
        "  top_n, top_i = output.topk(1)\n",
        "  language_i = top_i[0].item()\n",
        "  return all_languages[language_i], language_i\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    language = randomChoice(all_languages)\n",
        "\n",
        "    random_language_names = language_names[language]\n",
        "    name = randomChoice(random_language_names)\n",
        "\n",
        "    language_tensor = torch.tensor([all_languages.index(language)], dtype=torch.long)\n",
        "    name_tensor = nameToTensor(name)\n",
        "\n",
        "    return language, name, language_tensor, name_tensor"
      ],
      "metadata": {
        "id": "G4RAJx1jEsQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, language_tensor, name_tensor, criterion, lr):\n",
        "    hidden = model.initHidden()\n",
        "\n",
        "    model.zero_grad()\n",
        "    for i in range(name_tensor.size()[0]):\n",
        "        output, hidden = model(name_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, language_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-lr)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "pstDss318TmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "lr = 0.005\n",
        "\n",
        "num_epochs = 200000\n",
        "current_loss = 0 \n",
        "all_losses = []\n",
        "print_every = 10000\n",
        "plot_every = 1000\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    language, name, language_tensor, name_tensor = randomTrainingExample()\n",
        "\n",
        "    output, loss = train(model, language_tensor, name_tensor, criterion, lr)\n",
        "\n",
        "    current_loss += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        guess, _ = languageFromOutput(output)\n",
        "        correct = '✓' if guess == language else '✗ (%s)' % language\n",
        "\n",
        "        print('%d %d%% %.4f %s | %s %s' % (epoch,\n",
        "                                           epoch / num_epochs * 100,\n",
        "                                           loss, \n",
        "                                           name, \n",
        "                                           guess,\n",
        "                                           correct))\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "metadata": {
        "id": "SFk5zALf8To6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0C8jB9et8TrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "lj-LFjkC8mO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(name):\n",
        "  with torch.no_grad():\n",
        "    hidden = model.initHidden()\n",
        "    name_tensor = nameToTensor(name)\n",
        "    for i in range(name_tensor.size()[0]):\n",
        "      output, hidden = model(name_tensor[i], hidden)\n",
        "  return output"
      ],
      "metadata": {
        "id": "96lZUZgu21yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(name, n_predictions):\n",
        "  predictions = []\n",
        "\n",
        "  output = test(name)\n",
        "  topv, topi = output.topk(n_predictions, 1, True)\n",
        "\n",
        "  for i in range(n_predictions):\n",
        "    value = topv[0][i].item()\n",
        "    language_index = topi[0][i].item()\n",
        "    preds = all_languages[language_index]\n",
        "    print('(%.2f) %s' % (value, preds))\n",
        "\n",
        "    predictions.append([value, preds])"
      ],
      "metadata": {
        "id": "mqJNS4H36uTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction('Dovesky', 5)"
      ],
      "metadata": {
        "id": "HxPRv6KA5JSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkWeO3JV5Kg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}