{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_vs_dog.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNRWTTRredHTlB769J3c43Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/image_classification/cat_vs_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will train a ConvNet to classify whether images contain either a dog or a cat using [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/overview) dataset. The dataset contains 25,000 images of dogs and cats (12,500 from each class).\n",
        "\n",
        "The process will be broken down into the following steps:\n",
        "\n",
        "    1. Load and visualize the dataset\n",
        "    2. Define a pre-trained model\n",
        "        1. Load in a pre-trained model\n",
        "        2. Freeze all the parameters, so that the network acts as a fixed feature extractor\n",
        "        3. Remove the last layer\n",
        "        4. Replace the last layer with a linear classifier\n",
        "    3. Define a loss function and optimizer\n",
        "    4. Train the model on the training dataset\n",
        "    5. Evaluate the performance of the trained model on the test dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "vWVRfRapFwYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle API key from your local machine\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "4ATDBPAnHZvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a kaggle dir, copy the API key to it\n",
        "# and make sure the file in only readable by yourself (chmod 600)\n",
        "!mkdir ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "a5WkrKsuSVqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use API command to download the dataset\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "id": "5wS8AX7kTCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncompress the dataset\n",
        "!unzip -qq dogs-vs-cats\n",
        "!unzip -qq train.zip\n",
        "!unzip -qq test1.zip"
      ],
      "metadata": {
        "id": "O60P7n6kTQnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "31mTXiC5TXQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available!\")\n",
        "\n",
        "device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "jeyC0O4pTn2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/train\")))\n",
        "print(len(os.listdir(\"/content/test1\")))"
      ],
      "metadata": {
        "id": "tm32hkDEUarH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import os, shutil, pathlib\n",
        "\n",
        "# path to dir where original dataset was uncompressed\n",
        "original_train_dir = pathlib.Path(\"train\")\n",
        "original_test_dir = pathlib.Path(\"test1\")\n",
        "\n",
        "# dir of the smaller dataset\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs\")\n",
        "\n",
        "def make_train_valid_subset(subset_name, original_dir, new_base_dir, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
        "\n",
        "def make_test_subset(subset_name, original_dir, new_base_dir, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
        "\n",
        "# make 3 subsets: trai, validation, test\n",
        "make_train_valid_subset(\"train\", original_train_dir, new_base_dir, start_index=0, end_index=10000)\n",
        "make_train_valid_subset(\"valid\", original_train_dir, new_base_dir, start_index=10000, end_index=12000)\n",
        "make_test_subset(\"test\", original_test_dir, new_base_dir, start_index=1, end_index=2000)"
      ],
      "metadata": {
        "id": "DoAwLrsNJTQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(new_base_dir, \"train\")\n",
        "valid_dir = os.path.join(new_base_dir, \"valid\")\n",
        "test_dir = os.path.join(new_base_dir, \"test\")"
      ],
      "metadata": {
        "id": "GdATJtvRP3Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# load and transform data using ImageFolder\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.Resize((244, 244)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "\n",
        "print(\"Number of training images: \", len(train_data))\n",
        "print(\"Number of validation images: \", len(valid_data))\n",
        "print(\"Number of test images: \", len(test_data))"
      ],
      "metadata": {
        "id": "GiKYV3qEidZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataloader parameters\n",
        "\n",
        "# number of subprocess to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "\n",
        "# prepare train and validation data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "# image classes in the dataset\n",
        "classes = train_data.classes\n",
        "print(classes)\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "id": "VTLdliuyJJzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize a batch of training data\n",
        "\n",
        "def imshow(img):\n",
        "  # unnormalize\n",
        "  img = np.transpose(img, (1,2,0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  img = std * img + mean\n",
        "  img = np.clip(img, 0, 1)\n",
        "  plt.imshow(img)\n",
        "\n",
        "# obtain one batch on training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "# convert images to numpy for display\n",
        "images = images.numpy() \n",
        "\n",
        "# plot the images in the batch along with the corresponding labels\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "# display 10 images\n",
        "for ind in np.arange(10):\n",
        "  ax = fig.add_subplot(2, 10/2, ind+1, xticks=[], yticks=[])\n",
        "  imshow(images[ind])\n",
        "  ax.set_title(classes[labels[ind]])"
      ],
      "metadata": {
        "id": "4ymrZ_H6VnYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "# load a pre-trained model\n",
        "model = models.resnet34(pretrained=True)\n",
        "\n",
        "# print out the model stracture\n",
        "print(model)"
      ],
      "metadata": {
        "id": "G65Sa8jPVnbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.fc.in_features)\n",
        "print(model.fc.out_features)"
      ],
      "metadata": {
        "id": "pX29YMwRVnec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze training for all features layers, so that the network acts as a fixed feature extractor\n",
        "# for param in model.parameters():\n",
        "#   param.requires_grad = False\n",
        "\n",
        "# freeze training for all features layers, except the batchnorm layers\n",
        "for name, param in model.named_parameters():\n",
        "  if (\"bn\" not in name):\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "IwFISQGUVnkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# replace final classification layer with a new one\n",
        "model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 512),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(),\n",
        "                         nn.Linear(512, num_classes))\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "gjLSO12uVnnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss() # categorical cross-entropy\n",
        "\n",
        "# specify optimizer\n",
        "params = model.parameters()\n",
        "optimizer = optim.Adam(params, lr=0.001)\n",
        "# learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ],
      "metadata": {
        "id": "mo5V3D6gVnqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "num_epochs = 30\n",
        "# track training loss\n",
        "train_loss, valid_loss = [], []\n",
        "# initialize tracker for min validation loss\n",
        "min_valid_loss = np.inf\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  running_train_loss = 0.0\n",
        "  running_valid_loss = 0.0\n",
        "\n",
        "  # --------- train the model -----------------\n",
        "  # set model to training mode\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, data in enumerate(train_loader):\n",
        "    # get the inputs, data is a list of [inputs, targets]\n",
        "    inputs, targets = data\n",
        "    # mode tensor to the right device\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(outputs, targets)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    # update training loss\n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "  # update learning rate\n",
        "  lr_scheduler.step()\n",
        "\n",
        "  # ---------- validate the model ------------\n",
        "  # set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # since we're not training, we don't need to calculate the gradients for out outputs\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
        "      # move tensor to the right device\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      # forward pass\n",
        "      outputs = model(inputs)\n",
        "      # calculate the batch loss\n",
        "      loss = criterion(outputs, targets)\n",
        "      # update validation loss\n",
        "      running_valid_loss += loss.item()\n",
        "\n",
        "  # calculate average loss over an epoch\n",
        "  running_train_loss = running_train_loss / len(train_loader)\n",
        "  running_valid_loss = running_valid_loss / len(valid_loader)\n",
        "\n",
        "  train_loss.append(running_train_loss)\n",
        "  valid_loss.append(running_valid_loss)\n",
        "\n",
        "  print(\"Epoch: {} \\tTraining loss: {:.6f} \\tValidation loss: {:.6f}\".format(epoch+1, running_train_loss, running_valid_loss))\n",
        "\n",
        "  # save model if validation loss has decressed\n",
        "  if running_valid_loss <= min_valid_loss:\n",
        "    print(\"Validation loss decressed ({:.6f} --> {:.6f}). Saving model ...\".format(min_valid_loss, running_valid_loss))\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    min_valid_loss = running_valid_loss\n",
        "\n",
        "print(\"Finished training!\")"
      ],
      "metadata": {
        "id": "1jUXjwh8Vnth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training and validation loss for each epoch\n",
        "epochs = range(1, num_epochs+1)\n",
        "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, valid_loss, 'b', label='Validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rol9ZwxtVnws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the performance of the trained model on the test dataset"
      ],
      "metadata": {
        "id": "2TboU1ptz-XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model with the lowest validation loss\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "id": "-A1iUVAa0D7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# track test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = [0 for i in range(len(classes))]\n",
        "class_total = [0 for i in range(len(classes))]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(outputs, targets)\n",
        "    # update test loss\n",
        "    test_loss += loss.item()\n",
        "    # convert output probabilities to predicted class\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    # compare predictions to true labels\n",
        "    correct_tensor = predictions.eq(targets.data.view_as(predictions))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each class\n",
        "    for i in range(len(targets)):\n",
        "      label = targets.data[i]\n",
        "      class_correct[label] += correct[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss / len(test_loader.dataset)\n",
        "print(\"Test loss (overall): {:6f}\\n\".format(test_loss))\n",
        "\n",
        "# print test accuracy for each classes\n",
        "for i in range(len(classes)):\n",
        "  if class_total[i] > 0:\n",
        "    accuracy = (100 * class_correct[i]) / class_total[i]\n",
        "    print(f'Test accuracy of {classes[i]:10s}: {accuracy:.1f} % ({np.sum(class_correct[i])}/{np.sum(class_total[i])})')\n",
        "\n",
        "# overall test accuracy\n",
        "test_acc = 100 * np.sum(class_correct) / np.sum(class_total)\n",
        "print(\"\\nTest accuracy (overall): %2d%% (%2d/%2d)\" % ( \n",
        "      test_acc, np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "aNFbj8NM0N3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "wF3_0yKlJGDQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}