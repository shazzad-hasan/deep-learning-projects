{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_vs_dog.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOgtorIFPAmIypbc3j0SktM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/image_classification/cat_vs_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will train a ConvNet to classify whether images contain either a dog or a cat using [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/overview) dataset. The dataset contains 25,000 images of dogs and cats (12,500 from each class).\n",
        "\n",
        "The process will be broken down into the following steps:\n",
        "\n",
        "    1. Load and visualize the dataset\n",
        "    2. Define a pre-trained model\n",
        "        1. Load in a pre-trained model\n",
        "        2. Freeze all the parameters, so that the network acts as a fixed feature extractor\n",
        "        3. Remove the last layer\n",
        "        4. Replace the last layer with a linear classifier\n",
        "    3. Define a loss function and optimizer\n",
        "    4. Train the model on the training dataset\n",
        "    5. Evaluate the performance of the trained model on the test dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "vWVRfRapFwYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle API key from your local machine\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "4ATDBPAnHZvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a kaggle dir, copy the API key to it\n",
        "# and make sure the file in only readable by yourself (chmod 600)\n",
        "!mkdir ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "a5WkrKsuSVqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use API command to download the dataset\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "id": "5wS8AX7kTCfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncompress the dataset\n",
        "!unzip -qq dogs-vs-cats\n",
        "!unzip -qq train.zip\n",
        "!unzip -qq test1.zip"
      ],
      "metadata": {
        "id": "O60P7n6kTQnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "31mTXiC5TXQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "  print(\"CUDA is available!\")\n",
        "else:\n",
        "  print(\"CUDA is not available!\")\n",
        "\n",
        "device = torch.device(\"cuda\") if train_on_gpu else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "jeyC0O4pTn2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(\"/content/train\")))\n",
        "print(len(os.listdir(\"/content/test1\")))"
      ],
      "metadata": {
        "id": "tm32hkDEUarH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import os, shutil, pathlib\n",
        "\n",
        "# path to dir where original dataset was uncompressed\n",
        "original_train_dir = pathlib.Path(\"train\")\n",
        "original_test_dir = pathlib.Path(\"test1\")\n",
        "\n",
        "# dir of the smaller dataset\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs\")\n",
        "\n",
        "def make_train_valid_subset(subset_name, original_dir, new_base_dir, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
        "\n",
        "def make_test_subset(subset_name, original_dir, new_base_dir, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
        "\n",
        "# make 3 subsets: trai, validation, test\n",
        "make_train_valid_subset(\"train\", original_train_dir, new_base_dir, start_index=0, end_index=2000)\n",
        "make_train_valid_subset(\"valid\", original_train_dir, new_base_dir, start_index=2000, end_index=3000)\n",
        "make_test_subset(\"test\", original_test_dir, new_base_dir, start_index=1, end_index=1000)"
      ],
      "metadata": {
        "id": "DoAwLrsNJTQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_test_subset(subset_name, original_dir, new_base_dir, start_index, end_index):\n",
        "  for category in (\"cat\", \"dog\"):\n",
        "    dir = new_base_dir / subset_name / category\n",
        "    os.makedirs(dir)\n",
        "    fnames = [f\"{i}.jpg\" for i in range(start_index, end_index)]\n",
        "    for fname in fnames:\n",
        "      shutil.copyfile(src = original_dir / fname, dst = dir / fname)\n",
        "\n",
        "make_test_subset(\"test\", original_test_dir, new_base_dir, start_index=1, end_index=1000)"
      ],
      "metadata": {
        "id": "nWyohBSVTp9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(new_base_dir, \"train\")\n",
        "valid_dir = os.path.join(new_base_dir, \"valid\")\n",
        "test_dir = os.path.join(new_base_dir, \"test\")"
      ],
      "metadata": {
        "id": "GdATJtvRP3Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# load and transform data using ImageFolder\n",
        "data_transform = transforms.Compose([\n",
        "        transforms.Resize((244, 244)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
        "\n",
        "print(\"Number of training images: \", len(train_data))\n",
        "print(\"Number of validation images: \", len(valid_data))\n",
        "print(\"Number of test images: \", len(test_data))"
      ],
      "metadata": {
        "id": "GiKYV3qEidZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VTLdliuyJJzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}