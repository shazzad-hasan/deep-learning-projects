{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN22yRqhdLF7CBcbUNnYr/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazzad-hasan/practice-deep-learning-with-pytorch/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will train a ConvNet to classify images from the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) database. The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes (airplane, automobile,bird, cat, deer,dog, frog, horse, ship, truck), with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The process will be broken down into the following steps:\n",
        "\n",
        "    1. Load and visualize the dataset\n",
        "    2. Define a neural network\n",
        "    3. Define a Loss function and optimizer\n",
        "    4. Train the model on the training dataset\n",
        "    5. Evaluate the performance of the trained model on the test dataset"
      ],
      "metadata": {
        "id": "QpkSmFBNkTRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "z-oXR6C9lD4v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if cuda in available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print(\"CUDA is not available\")\n",
        "else:\n",
        "  print(\"CUDA is available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oj1ub4F8z94",
        "outputId": "4e7ddca8-b347-410f-92e7-9ccf92db108f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and visualize the dataset"
      ],
      "metadata": {
        "id": "alb7Q-PdnHDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRndomSampler\n",
        "\n",
        "\n",
        "# convert the data to a normalized torch.FloatTensor\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
        "\n",
        "# choose the training and test dataset\n",
        "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# obtain training indices for creating a validation dataset\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "# choose percentage of training data for validation\n",
        "valid_size = 0.2\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# number of subprocesses \n",
        "\n",
        "# prepare train, test and valid data loaders\n",
        "train_loaders = torch.utils.data.DataLoader(train_data, batch_size, sampler=train_sampler, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "3NULsF2tpS1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aBXdccVRpS9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TNlqCWWLpTAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hCYHadmQpTDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V948TbmLpTGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AbuZICF8pTJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hDgp-jZwpTL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eJD88X2RpTOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iOcXWyklpTRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PpzbjVafpTUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uVx5ATfppTXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}